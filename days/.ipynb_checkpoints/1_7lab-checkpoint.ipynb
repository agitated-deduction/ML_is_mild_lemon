{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 기사 분류: 다중 분류 문제\n",
    "\n",
    "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/%EC%BC%80%EB%9D%BC%EC%8A%A4-%EB%94%A5%EB%9F%AC%EB%8B%9D/) 책의 3장 5절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다.\n",
    "\n",
    "----\n",
    "\n",
    "이전 섹션에서 완전 연결된 신경망을 사용해 벡터 입력을 어떻게 두 개의 클래스로 분류하는지 보았습니다. 두 개 이상의 클래스가 있을 때는 어떻게 해야 할까요?\n",
    "\n",
    "이 절에서 로이터 뉴스를 46개의 상호 배타적인 토픽으로 분류하는 신경망을 만들어 보겠습니다. 클래스가 많기 때문에 이 문제는 다중 분류의 예입니다. 각 데이터 포인트가 정확히 하나의 범주로 분류되기 때문에 좀 더 정확히 말하면 단일 레이블 다중 분류 문제입니다. 각 데이터 포인트가 여러 개의 범주(가령, 토픽)에 속할 수 있다면 이런 문제는 다중 레이블 다중 분류의 문제가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로이터 데이터셋\n",
    "\n",
    "1986년에 로이터에서 공개한 짧은 뉴스 기사와 토픽의 집합인 로이터 데이터셋을 사용하겠습니다. 이 데이터셋은 텍스트 분류를 위해 널리 사용되는 간단한 데이터셋입니다. 46개의 토픽이 있으며 어떤 토픽은 다른 것에 비해 데이터가 많습니다. 각 토픽은 훈련 세트에 최소한 10개의 샘플을 가지고 있습니다.\n",
    "\n",
    "IMDB와 MNIST와 마찬가지로 로이터 데이터셋은 케라스에 포함되어 있습니다. 한 번 살펴보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 3s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB 데이터셋에서처럼 num_words=10000 매개변수는 데이터에서 가장 자주 등장하는 단어 10,000개로 제한합니다.\n",
    "\n",
    "여기에는 8,982개의 훈련 샘플과 2,246개의 테스트 샘플이 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB 리뷰처럼 각 샘플은 정수 리스트입니다(단어 인덱스):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "궁금한 경우를 위해 어떻게 단어로 디코딩하는지 알아보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 1s 2us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플에 연결된 레이블은 토픽의 인덱스로 0과 45 사이의 정수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "이전의 예제와 동일한 코드를 사용해서 데이터를 벡터로 변환합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "# 훈련 데이터 벡터 변환\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# 테스트 데이터 벡터 변환\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블을 벡터로 바꾸는 방법은 두 가지입니다. 레이블의 리스트를 정수 텐서로 변환하는 것과 원-핫 인코딩을 사용하는 것입니다. 원-핫 인코딩이 범주형 데이터에 널리 사용되기 때문에 범주형 인코딩이라고도 부릅니다. 원-핫 인코딩에 대한 자세한 설명은 6.1절을 참고하세요. 이 경우 레이블의 원-핫 인코딩은 각 레이블의 인덱스 자리는 1이고 나머지는 모두 0인 벡터입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "# 훈련 레이블 벡터 변환\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "# 테스트 레이블 벡터 변환`\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982, 46)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 예제에서 이미 보았듯이 케라스에는 이를 위한 내장 함수가 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982, 46)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train_labels.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구성\n",
    "\n",
    "이 토픽 분류 문제는 이전의 영화 리뷰 분류 문제와 비슷해 보입니다. 두 경우 모두 짧은 텍스트를 분류하는 것이죠. 여기에서는 새로운 제약 사항이 추가되었습니다. 출력 클래스의 개수가 2에서 46개로 늘어난 점입니다. 출력 공간의 차원이 훨씬 커졌습니다.\n",
    "\n",
    "이전에 사용했던 것처럼 `Dense` 층을 쌓으면 각 층은 이전 층의 출력에서 제공한 정보만 사용할 수 있습니다. 한 층이 분류 문제에 필요한 일부 정보를 누락하면 그 다음 층에서 이를 복원할 방법이 없습니다. 각 층은 잠재적으로 정보의 병목이 될 수 있습니다. 이전 예제에서 16차원을 가진 중간층을 사용했지만 16차원 공간은 46개의 클래스를 구분하기에 너무 제약이 많을 것 같습니다. 이렇게 규모가 작은 층은 유용한 정보를 완전히 잃게 되는 정보의 병목 지점처럼 동작할 수 있습니다.\n",
    "\n",
    "이런 이유로 좀 더 규모가 큰 층을 사용하겠습니다. 64개의 유닛을 사용해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 구조에서 주목해야 할 점이 두 가지 있습니다:\n",
    "\n",
    "* 마지막 `Dense` 층의 크기가 46입니다. 각 입력 샘플에 대해서 46차원의 벡터를 출력한다는 뜻입니다. 이 벡터의 각 원소(각 차원)은 각기 다른 출력 클래스가 인코딩된 것입니다.\n",
    "* 마지막 층에 `softmax` 활성화 함수가 사용되었습니다. MNIST 예제에서 이런 방식을 보았습니다. 각 입력 샘플마다 46개의 출력 클래스에 대한 확률 분포를 출력합니다. 즉, 46차원의 출력 벡터를 만들며 `output[i]`는 어떤 샘플이 클래스 `i`에 속할 확률입니다. 46개의 값을 모두 더하면 1이 됩니다.\n",
    "\n",
    "이런 문제에 사용할 최선의 손실 함수는 `categorical_crossentropy`입니다. 이 함수는 두 확률 분포의 사이의 거리를 측정합니다. 여기에서는 네트워크가 출력한 확률 분포와 진짜 레이블의 분포 사이의 거리입니다. 두 분포 사이의 거리를 최소화하면 진짜 레이블에 가능한 가까운 출력을 내도록 모델을 훈련하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 검증\n",
    "\n",
    "훈련 데이터에서 1,000개의 샘플을 따로 떼어서 검증 세트로 사용하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7982"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(partial_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 20번의 에포크로 모델을 훈련시킵니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 2s 200us/step - loss: 2.6325 - accuracy: 0.5199 - val_loss: 1.7579 - val_accuracy: 0.6360\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 138us/step - loss: 1.4204 - accuracy: 0.7134 - val_loss: 1.3169 - val_accuracy: 0.7080\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 145us/step - loss: 1.0420 - accuracy: 0.7818 - val_loss: 1.1506 - val_accuracy: 0.7470\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 141us/step - loss: 0.8237 - accuracy: 0.8245 - val_loss: 1.0294 - val_accuracy: 0.7920\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 140us/step - loss: 0.6490 - accuracy: 0.8683 - val_loss: 0.9878 - val_accuracy: 0.7880\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 137us/step - loss: 0.5218 - accuracy: 0.8930 - val_loss: 0.9249 - val_accuracy: 0.8060\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 0.4201 - accuracy: 0.9112 - val_loss: 0.9279 - val_accuracy: 0.8010\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 142us/step - loss: 0.3398 - accuracy: 0.9258 - val_loss: 0.9006 - val_accuracy: 0.8170\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 142us/step - loss: 0.2813 - accuracy: 0.9379 - val_loss: 0.9025 - val_accuracy: 0.8200\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 0.2388 - accuracy: 0.9431 - val_loss: 0.8974 - val_accuracy: 0.8230\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 0.2059 - accuracy: 0.9485 - val_loss: 0.9410 - val_accuracy: 0.8100\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 135us/step - loss: 0.1797 - accuracy: 0.9520 - val_loss: 0.9552 - val_accuracy: 0.8170\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 0.1630 - accuracy: 0.9533 - val_loss: 0.9675 - val_accuracy: 0.8240\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 149us/step - loss: 0.1519 - accuracy: 0.9546 - val_loss: 0.9784 - val_accuracy: 0.8170\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 139us/step - loss: 0.1386 - accuracy: 0.9573 - val_loss: 0.9805 - val_accuracy: 0.8170\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 0.1327 - accuracy: 0.9558 - val_loss: 1.0234 - val_accuracy: 0.8120\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 138us/step - loss: 0.1243 - accuracy: 0.9559 - val_loss: 1.0136 - val_accuracy: 0.8190\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 138us/step - loss: 0.1187 - accuracy: 0.9565 - val_loss: 1.0387 - val_accuracy: 0.8100\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 149us/step - loss: 0.1143 - accuracy: 0.9563 - val_loss: 1.0565 - val_accuracy: 0.8110\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 142us/step - loss: 0.1127 - accuracy: 0.9583 - val_loss: 1.0783 - val_accuracy: 0.8070\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실과 정확도 곡선을 그려 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZwU1bn/8c/DLrIPKsoy4L4g4DiiRtyi4YIbiRqRkLigQU3A5Wruj4iJxCUxbteNGHGLxlGCGo3muhOUGGNkUHYUEEFHkF0EWQee3x+nBnqa7pmepbtnpr/v16te3VV1qvrpmp56qk6dOmXujoiI5K5G2Q5ARESyS4lARCTHKRGIiOQ4JQIRkRynRCAikuOUCEREcpwSgezCzBqb2Xoz61abZbPJzPY3s1pvK21mp5rZopjxT8zs+FTKVuOzHjGz66u7vEgyTbIdgNScma2PGW0JbAa2ReOXuXtRVdbn7tuAVrVdNhe4+0G1sR4zuxT4sbufFLPuS2tj3SLxlAgaAHffsSOOjjgvdfe3kpU3sybuXpqJ2EQqo99j9qlqKAeY2S1m9hcze8bM1gE/NrNjzex9M/vazJaa2X1m1jQq38TM3My6R+NPRfNfNbN1ZvZvM+tR1bLR/IFmNs/M1prZ/Wb2LzO7KEncqcR4mZktMLM1ZnZfzLKNzex/zWyVmX0KDKhg+9xgZuPjpo01s7uj95ea2dzo+3waHa0nW1eJmZ0UvW9pZn+OYpsNHJngcxdG651tZmdF0w8HHgCOj6rdVsZs2zExy18effdVZvaime2dyrapynYui8fM3jKz1Wb2lZn9T8zn/CraJt+YWbGZ7ZOoGs7M3i37O0fbc3L0OauBG8zsADObFH2XldF2axuzfH70HVdE8+81sxZRzIfElNvbzDaYWV6y7ysJuLuGBjQAi4BT46bdAmwBziQk/92Ao4CjCWeF+wLzgBFR+SaAA92j8aeAlUAh0BT4C/BUNcruCawDBkXz/hvYClyU5LukEuPfgLZAd2B12XcHRgCzgS5AHjA5/NwTfs6+wHpg95h1LwcKo/EzozIGfBfYCPSK5p0KLIpZVwlwUvT+TuBtoD2QD8yJK3sesHf0N/lRFMNe0bxLgbfj4nwKGBO97x/F2AdoAfwB+Ecq26aK27ktsAy4CmgOtAH6RvN+CUwHDoi+Qx+gA7B//LYG3i37O0ffrRS4AmhM+D0eCJwCNIt+J/8C7oz5PrOi7bl7VP64aN444NaYz7kWeCHb/4f1bch6ABpq+Q+aPBH8o5LlrgOejd4n2rn/MabsWcCsapQdBvwzZp4BS0mSCFKM8ZiY+X8FroveTyZUkZXNOy1+5xS37veBH0XvBwLzKij7d+Dn0fuKEsHnsX8L4GexZROsdxZwevS+skTwBPDbmHltCNeFulS2baq4nX8CFCcp92lZvHHTU0kECyuJ4VxgSvT+eOAroHGCcscBnwEWjU8Dzq7t/6uGPqhqKHd8ETtiZgeb2f9Fp/rfADcBHStY/quY9xuo+AJxsrL7xMbh4T+3JNlKUowxpc8CFlcQL8DTwJDo/Y+AHRfYzewMM/tPVDXyNeFovKJtVWbvimIws4vMbHpUvfE1cHCK64Xw/Xasz92/AdYAnWPKpPQ3q2Q7dwUWJImhKyEZVEf877GTmU0wsy+jGP4UF8MiDw0TynH3fxHOLvqZWU+gG/B/1YwpZykR5I74ppMPEY5A93f3NsCvCUfo6bSUcMQKgJkZ5Xdc8WoS41LCDqRMZc1b/wKcamZdCFVXT0cx7gY8B/yOUG3TDngjxTi+ShaDme0LPEioHsmL1vtxzHora+q6hFDdVLa+1oQqqC9TiCteRdv5C2C/JMslm/dtFFPLmGmd4srEf7/fE1q7HR7FcFFcDPlm1jhJHE8CPyacvUxw981JykkSSgS5qzWwFvg2uth2WQY+8+9AgZmdaWZNCPXOe6QpxgnA1WbWObpw+P8qKuzuywjVF48Dn7j7/GhWc0K99Qpgm5mdQajLTjWG682snYX7LEbEzGtF2BmuIOTESwlnBGWWAV1iL9rGeQa4xMx6mVlzQqL6p7snPcOqQEXb+SWgm5mNMLNmZtbGzPpG8x4BbjGz/SzoY2YdCAnwK0KjhMZmNpyYpFVBDN8Ca82sK6F6qsy/gVXAby1cgN/NzI6Lmf9nQlXSjwhJQapIiSB3XQtcSLh4+xDhiDitop3tYOBuwj/2fsBHhCPB2o7xQWAiMBOYQjiqr8zThDr/p2Ni/hq4BniBcMH1XEJCS8WNhDOTRcCrxOyk3H0GcB/wQVTmYOA/Mcu+CcwHlplZbBVP2fKvEapwXoiW7wYMTTGueEm3s7uvBb4HnEO4OD0PODGafQfwImE7f0O4cNsiqvL7KXA9oeHA/nHfLZEbgb6EhPQS8HxMDKXAGcAhhLODzwl/h7L5iwh/5y3u/l4Vv7uw8wKLSMZFp/pLgHPd/Z/ZjkfqLzN7knABeky2Y6mPdEOZZJSZDSCc6m8iND8sJRwVi1RLdL1lEHB4tmOpr1Q1JJnWD1hIqDIYAHxfF/ekuszsd4R7GX7r7p9nO576SlVDIiI5TmcEIiI5rt5dI+jYsaN3794922GIiNQrU6dOXenuCZtr17tE0L17d4qLi7MdhohIvWJmSe+uV9WQiEiOUyIQEclxSgQiIjlOiUBEJMcpEYiI5DglAhGROq6oCLp3h0aNwmtRUWVLVI0SgYikXU13ZLm8fFERDB8OixeDe3gdPryWk0G2H5FW1eHII490Ecmsp55yz893NwuvTz1VtWVbtnQPu7EwtGyZ+jpyffn8/PLLlg35+aktX4Ykjxx1r4fPLFYikFxUkx1xTZfP9o4s15c3S7y8WWrLl6koEdS7TucKCwtddxZLLimrGtiwYee0li1h3DgYmsKjaGq6fPfuoToiXn4+LFpU+fKNGoVdVzwz2L5dy1emptt/5+fZVHcvTBhj6qsRkeqoaf3y6NHld+IQxkePzszynyfp3DnZ9HjdkjwtOtl0LV/erbeGxB2rZcswvdYkO1Woq4OqhqQ+qWm1invNqwZqunxNqzayXcde35cvW0dNqgbdK64ayvqOvaqDEoFkWk3+CWvjQl+266jrwo4s15evDUoEItVU051gbVzoayhHpJJdSgSS07J5RF9bTf8awhGpZFdFiUCthqRBq2mLmZq2+Kjp54vUFrUakpxV0xYzNW3xMXRo2Onn54fkkZ+vJCB1jxKBNGg1bfpYG033hg4N7b23bw+vSgJS1ygRSIOmI3qRyikRSIOmI3qRyikRSJ1XkztzdUQvUrkm2Q5ApCLxrW7KuuCF1HfmQ4dqxy9SEZ0RSJ1W01Y/IlI5JQKp02ra6kdEKqdEIHVaTVv9iEjllAikTstIF7wiOU6JQNJOrX5E6ja1GpK0UqsfkbpPZwSSVmr1I1L3KRFIWqnVj0jdp0QgaaVWPyJ1X1oTgZkNMLNPzGyBmY1KMD/fzCaa2Qwze9vMuqQzHsk8tfoRqfvSlgjMrDEwFhgIHAoMMbND44rdCTzp7r2Am4DfpSseyQ61+hGp+9LZaqgvsMDdFwKY2XhgEDAnpsyhwDXR+0nAi2mMR7JErX5E6rZ0Vg11Br6IGS+JpsWaDpwTvf8B0NrM8tIYk4iIxElnIrAE0+Kf/nodcKKZfQScCHwJlO6yIrPhZlZsZsUrVqyo/UilQjW5IUxE6r50Vg2VAF1jxrsAS2ILuPsS4GwAM2sFnOPua+NX5O7jgHEQHl6froBlV7VxQ5iI1G3pPCOYAhxgZj3MrBlwPvBSbAEz62hmZTH8EngsjfFINeiGMJGGL22JwN1LgRHA68BcYIK7zzazm8zsrKjYScAnZjYP2AtQo8I6RjeEiTR8ae1ryN1fAV6Jm/brmPfPAc+lMwapmW7dQnVQouki0jDozmKpkG4IE2n4lAikQrohTKThUzfUUindECbSsOmMQEQkxykRiIjkOCUCEZEcp0SQA9RFhIhURBeLGzh1ESEildEZQQOnLiJEpDJKBA2cuogQkcooETRwemawiFRGiaCBUxcRIlIZJYIGTl1EiEhl1GooB6iLCBGpiM4IRERynBKBiEiOUyIQEclxSgQiIjlOiUBEJMcpEYiI5DglAhGRHKdEICKS45QIRERynBKBiEiOUyIQEclxSgQiIjlOiaAe0DOHRSSd1PtoHadnDotIupm7ZzuGKiksLPTi4uJsh5Ex3buHnX+8/HxYtCjT0eSG0lJYtQpWrIDly8OwYgVs3AgDB8Lhh2c7wspt3Qpz58LUqfDhh2GYNw/22w+OPBIKCsLroYdCs2bZjlYywcymunthwnlKBHVbo0aQ6E9kBtu3Zz6e+mj7dli9eueOPX4HHz9t9erE27xMnz5wwQUwZAh06pS575HMli0wa1bY2Zft+KdPh82bw/xWreCII+DAA2HBgjB/3bowr1kz6NVrZ2IoKAiJrnnz7H0fSQ8lgnpMZwS7coe1ayvemcdOW7kStm1LvK4OHWDPPcOwxx7lX+Pfb9sGzz4LTz4JU6ZA48bQv39ICoMGwW67pf+7b9oEM2aU3+nPnBnOAADatg0787LhyCPhgAPCAUWZ7dvh00/Lr2PqVPj66zC/SRPo2bP8mUOvXpn5frXJHZYs2fn9Pv4YDj4YTj4Zjjkm95KdEkE9Fn+NAMIzh3PpcZNr18LDD8P48bB0adi5l+344rVtW/lOvew1Lw+aNq1eTB9/DH/+cxi++AJat4Yf/hB+8hM44YTyO97q2rAhHNnH7qxnz96Z1Dp0KH8kf+SR0KNH9T7bPRxYxH7W1KmhigxC0jvwwF2ff10VjRpBt26w//7lh332qfn2cofPPy+f3D78EJYtC/PNoGvX8LdyhxYt4DvfCUnh5JPhqKMafhWZEkE9V1QEo0eHH3q3buHB87mQBBYvhnvvhUceCVUZ3/lOOKJLtmPv2DHzR3nbt8M774SE8OyzsH59+Bv95CdhOOig1Nazbh1Mm1Z+R/zxxzur//bYY+fOvmzHX/Yc6nRxh5KSnTHNmhWqoapr69bwG164sPx6WrQI1y5ik0PZeLduIQnFx7Vw4a47/dikdeih5RNk796w++6wZg1Mngxvvw2TJoVECyHBHXfczsRQWBjOjBoSJQKpV4qL4a67wo7VDAYPhmuvDfXcddmGDfDiiyEpvPFG2In37RuqjgYPDokKQhXMRx+V35HNm7fzusTee5ffiRUUQOfO6d3pZ9K2bSHBLFiQeNi0aWfZpk3DWc7++0OXLjB/fthea9funB9fjXX44alXY61aFRL5pElhmD07TG/VCo4/PiSFk04K645PSKnYvj1cq9m8OSTC9u2zl2CUCKTO274d/v73kAAmT4Y2beCyy2DkyHBKX98sXQpPPx2uJ8yYEf75+/ULVROffrqzXNeu5Xf4BQUhEeSq7dvDtkuUIL74Avbdt/y26tmzds8Cly8vnxg+/jhMb9MmnDG0bLlzxx47bNqUeHp8FWajRuHv27Vr+aFLl53v99qrekmnMkoEUmdt3Bh2lnffHY6Ku3WDq6+GSy4J/3wNwfTp4Sxh4sTyzTcLCkKVj9RdS5eGaqS334Z//zs0LW7ePFRnNW++c4gfTzStSZOQaEpKQlIrGzZuLP+ZTZqEM8D4BNG1a6iy6tKlet8la4nAzAYA9wKNgUfc/ba4+d2AJ4B2UZlR7v5KRetUIsi8devgvvtCtUfnzrte7OvatepHMMuXw9ix8Ic/hFY9hYWh+ufccxte3axIMu6huXJ8cvjii53TSkp2NgV+8EG4/PLqfVZFiSBt/3Jm1hgYC3wPKAGmmNlL7j4nptgNwAR3f9DMDgVeAbqnKyapmvXr4YEH4I47wo/12GNDtcbrr+9aj7vvvrsmiP33Dxc0Y1vmfPxxOPp/8snw4z7zTLjuulAf21DqwEVSZRZar+XlhQvaibiHlnIlJeFALB3SeezVF1jg7gsBzGw8MAiITQQOlFUAtAWWpDEeSdG334Yj9dtvD0frp50GY8aEJnZQcT3uO++EBFKmceNwL8T++4fl3nwznDJfdBFcc03qrWpEcpXZzpZy6ZLORNAZ+CJmvAQ4Oq7MGOANMxsJ7A6cmsZ4pBIbN8If/wi33Raqbvr3h9/8Jtx8E6tRo3Bk0rkznHhi+XnuYdn4BDF/fmgtM2YM/OxnqhsXqUvSmQgSnejHX5AYAvzJ3e8ys2OBP5tZT3cv13mCmQ0HhgN069YtLcHmsk2bwg1qv/sdfPUVnHJKSADHHVf1dZmFVg977VW95UUk89LZDXUJENvwrwu7Vv1cAkwAcPd/Ay2AjvErcvdx7l7o7oV76FCy1mzeHKqA9t8frroq3Dn69tvw1lvaiYvkknSeEUwBDjCzHsCXwPnAj+LKfA6cAvzJzA4hJIIVaYyp3vrqK3jiCWjXrnyzsnbtqn6RdcsWePzxcIfyF1+E9u1PPhluntEFW5Hck7ZE4O6lZjYCeJ3QNPQxd59tZjcBxe7+EnAt8LCZXUOoNrrI69uNDRmwaROccUa4CzXe7rsnvikldlpZe/ytW8MO/+abQ/cNxxwDjz4Kp56qBCCSy9LaYju6J+CVuGm/jnk/B1AlRAXcw8XVqVPhr38NLXeStTeeNSucOcSn0jZtQlJYty709XLUUeGi8H/9lxKAiOgJZRlRk07jxo0L1Ti/+hX84AdhWpcuoU1/Ilu2hKadiZLF5s3hJq7TT1cCEJGdlAjSrCaPmnz//dDXzsCBcOONqX1es2bhJq78/OrHLCK5pdJWQ2Y2wszaZyKYhmj06PLPEoAwPnp0xcstWwbnnBOqdJ56Kj2dUImIQGrNRzsRuoeYYGYDzFSpUBWff1616RAu6p53Xug7/a9/DQ8gERFJl0oTgbvfABwAPApcBMw3s9+a2X5pjq1BSHb/W0X3xf3iF6Er5ocfTt7/iIhIbUnphrKoSedX0VAKtAeeM7Pb0xhbg3Drrbs+3q9lyzA9kaKi8FSuq67KjaeQiUj2pXKN4EozmwrcDvwLONzdrwCOBM5Jc3z13tChoeVP2WMF8/OTP294+nT46U9DT5x33JH5WEUkN6XSaqgjcLa7L46d6O7bzeyM9ITVsAwdWvnR/erVoXlo+/YwYUL1H6ouIlJVqVQNvQKsLhsxs9ZmdjSAu89NV2C5ZNu2kChKSuD556FTp2xHJCK5JJVE8CAQ08M830bTpJb85jfw2mtw//27dvksIpJuqSQCi+3/J+oiWjei1ZKXXgp9/wwbtvNGMxGRTEolESyMLhg3jYargIXpDiwXzJsHP/lJeF7v2LHq9kFEsiOVRHA58B1CV9JlTxnTsWsNrVsXLg43axauC7Roke2IRCRXVVrF4+7LCc8SkFriHqqCPv4Y3nij4pvLRETSrdJEYGYtCE8SO4zw4BgA3H1YGuNq0O68E557Ljwc/pRTsh2NiOS6VKqG/kzob+i/gHcIj5xcl86gGrKJE2HUKDj3XLjuumxHIyKSWiLY391/BXzr7k8ApwOHpzeshmnxYhg8GA4+GB57TBeHRaRuSCURbI1evzaznkBboHvaImqgNm0K3Upv3QovvACtW2c7IhGRIJX7AcZFzyO4AXgJaAX8Kq1RNTDbtsEFF4THTf7tb3DggdmOSERkpwoTgZk1Ar5x9zXAZGDfjETVgLjDlVfCs8+Gi8RnnZXtiEREyquwaii6i3hEhmJpkG66Cf7wh/CMgWuvzXY0IiK7SuUawZtmdp2ZdTWzDmVD2iNrAP74RxgzBi68EH7/+2xHIyKSWCrXCMruF/h5zDRH1UQVeu45+NnP4PTTw5PG1EJIROqqVO4s7pGJQBqSf/wjdCt97LF6toCI1H2p3Fl8QaLp7v5k7YdT/330EXz/+3DAAfDyy7s+plJEpK5JpWroqJj3LYBTgA8BJYI4CxbAgAHhKWOvvw4ddCVFROqBVKqGRsaOm1lbQrcTEmPpUujfP9wz8Prr0LlztiMSEUlNdR4wswE4oLYDqc/WroWBA2H58nB94OCDsx2RiEjqUrlG8DKhlRCE5qaHAhPSGVR9smkTDBoEs2fD//0f9O2b7YhERKomlTOCO2PelwKL3b0kTfHUK9u2wY9+BO+8A08/HaqGRETqm1QSwefAUnffBGBmu5lZd3dflNbI6jh3uOKK0IHcvffCkCHZjkhEpHpSubP4WWB7zPi2aFrOKCqC7t2hUaPwWlQEv/51uFHs+utDX0IiIvVVKmcETdx9S9mIu28xs2ZpjKlOKSqC4cNhw4YwvngxXHxx6E760kvhlluyG5+ISE2lckawwsx29JlpZoOAlekLqW4ZPXpnEiizdSvsths8+KC6jhCR+i+VM4LLgSIzeyAaLwES3m3cEH3+eeLpGzdCk+o0vhURqWNSuaHsU+AYM2sFmLvn1POKu3UL1UHx8vMzH4uISDpUWjVkZr81s3buvt7d15lZezPLmZrxW2/dtb+gli3DdBGRhiCVawQD3f3rspHoaWWnpbJyMxtgZp+Y2QIzG5Vg/v+a2bRomGdmXydaTzYNHQr/8z87x/PzYdy4MF1EpCFIpZa7sZk1d/fNEO4jAJpXtpCZNQbGAt8jXFeYYmYvufucsjLufk1M+ZHAEVWMPyM++ADy8mDRImjVKtvRiIjUrlTOCJ4CJprZJWZ2CfAm8EQKy/UFFrj7wqj56XhgUAXlhwDPpLDejCouhldeCY+ZVBIQkYYolYvFt5vZDOBUwIDXgFQulXYGvogZLwGOTlTQzPKBHsA/kswfDgwH6NatWwofXXtuuil0Jz1CT24WkQYqlTMCgK8IdxefQ3gewdwUlknUwt4TTAM4H3jO3bclmunu49y90N0L99hjj1TirRUffRQeLnPNNdC6dcY+VkQko5KeEZjZgYQd9BBgFfAXQvPRk1NcdwnQNWa8C7AkSdnzKf9M5Drh5puhXTsYObLysiIi9VVFZwQfE47+z3T3fu5+P6GfoVRNAQ4wsx5RlxTnAy/FFzKzg4D2wL+rsO60mzEjdCh39dXQtm22oxERSZ+KEsE5hCqhSWb2sJmdQuLqnoTcvRQYAbxOqEqa4O6zzeym2C4rCGcc4909WbVRVtx8M7Rpow7lRKThs8r2v2a2O/B9wg77u4QWQy+4+xvpD29XhYWFXlxcnNbPmDULDj8cbrghJAQRkfrOzKa6e2GieZVeLHb3b929yN3PINTzTwN2uTmsIbnlltBU9JprKi8rIlLfpdpqCAB3X+3uD7n7d9MVULbNnQsTJoQLxB06ZDsaEZH0q1IiyAVlfQv9939nOxIRkcxQIogxbx488wz8/OfQsWO2oxERyQwlghi33grNm4fuJEREcoUSQWTBgvBYyiuugD33zHY0IiKZo0QQ+d3voGlT+MUvsh2JiEhmKREAn30GTz4Jl10GnTplOxoRkcxSIiCcDTRuXP4BNCIiuSLnE8HixfCnP8Gll8I++2Q7GhGRzMv5RHDbbWAGoxr0vdIiIsnldCL44gt49FEYNgy6dMl2NCIi2ZHTieD228OrzgZEJJflbCJYsgQefhguugjyU3nwpohIA5WzieD226G0FH75y2xHIiKSXTmZCL76Ch56CC64AHr0yHY0IiLZlZOJ4M47YetWGD0625GIiGRfziWC5cvhD3+AoUNhv/2yHY2ISPblXCK46y7YvFlnAyIiZXIqEaxcCWPHwpAhcOCB2Y5GRKRuyKlEcPfdsGGDzgZERGLlTCJYvRruvx/OOw8OOSTb0YiI1B05kwjuuw/Wr4df/SrbkYiI1C1Nsh1ApowcCQcdBIcdlu1IRETqlpw5I8jLCxeJRUSkvJxJBCIikpgSgYhIjlMiEBHJcUoEIiI5TolARCTHKRGIiOQ4JQIRkRynRCAikuOUCEREcpwSgYhIjlMiEBHJcWlNBGY2wMw+MbMFZjYqSZnzzGyOmc02s6fTGY+IiOwqbb2PmlljYCzwPaAEmGJmL7n7nJgyBwC/BI5z9zVmtme64hERkcTSeUbQF1jg7gvdfQswHhgUV+anwFh3XwPg7svTGI+IiCSQzkTQGfgiZrwkmhbrQOBAM/uXmb1vZgMSrcjMhptZsZkVr1ixIk3hiojkpnQmAkswzePGmwAHACcBQ4BHzKzdLgu5j3P3Qncv3GOPPWo9UBGRXJbORFACdI0Z7wIsSVDmb+6+1d0/Az4hJAYREcmQdCaCKcABZtbDzJoB5wMvxZV5ETgZwMw6EqqKFqYxJhERiZO2RODupcAI4HVgLjDB3Web2U1mdlZU7HVglZnNASYBv3D3VemKSUREdmXu8dX2dVthYaEXFxdnOwwRkXrFzKa6e2GiebqzWEQkxykRiIjkuLTdWSwiDcvWrVspKSlh06ZN2Q5FKtCiRQu6dOlC06ZNU15GiUBEUlJSUkLr1q3p3r07ZoluE5Jsc3dWrVpFSUkJPXr0SHk5VQ2JSEo2bdpEXl6ekkAdZmbk5eVV+axNiUBEUqYkUPdV52+kRCAikuOUCEQkLYqKoHt3aNQovBYV1Wx9q1atok+fPvTp04dOnTrRuXPnHeNbtmxJaR0XX3wxn3zySYVlxo4dS1FNg61ndLFYRGpdUREMHw4bNoTxxYvDOMDQodVbZ15eHtOmTQNgzJgxtGrViuuuu65cGXfH3WnUKPEx7uOPP17p5/z85z+vXoD1mM4IRKTWjR69MwmU2bAhTK9tCxYsoGfPnlx++eUUFBSwdOlShg8fTmFhIYcddhg33XTTjrL9+vVj2rRplJaW0q5dO0aNGkXv3r059thjWb48PA7lhhtu4J577tlRftSoUfTt25eDDjqI9957D4Bvv/2Wc845h969ezNkyBAKCwt3JKlYN954I0cdddSO+Mp6cpg3bx7f/e536d27NwUFBSxatAiA3/72txx++OH07t2b0enYWEkoEYhIrfv886pNr6k5c+ZwySWX8NFHH9G5c2duu+02iouLmT59Om+++SZz5szZZZm1a9dy4oknMn36dI499lgee+yxhOt2dz744APuuOOOHUnl/vvvp1OnTkyfPp1Ro0bx0UcfJVz2qquuYsqUKcycOZO1a9fy2muvATBkyBCuueYapk+fznvvvceee+7JyyLskgIAAA8WSURBVC+/zKuvvsoHH3zA9OnTufbaa2tp61ROiUBEal23blWbXlP77bcfRx111I7xZ555hoKCAgoKCpg7d27CRLDbbrsxcOBAAI488sgdR+Xxzj777F3KvPvuu5x//vkA9O7dm8MOOyzhshMnTqRv37707t2bd955h9mzZ7NmzRpWrlzJmWeeCYQbwFq2bMlbb73FsGHD2G233QDo0KFD1TdENSkRiEitu/VWaNmy/LSWLcP0dNh99913vJ8/fz733nsv//jHP5gxYwYDBgxI2K6+WbNmO943btyY0tLShOtu3rz5LmVS6axzw4YNjBgxghdeeIEZM2YwbNiwHXEkauLp7llrnqtEICK1buhQGDcO8vPBLLyOG1f9C8VV8c0339C6dWvatGnD0qVLef3112v9M/r168eECRMAmDlzZsIzjo0bN9KoUSM6duzIunXreP755wFo3749HTt25OWXXwbCjXobNmygf//+PProo2zcuBGA1atX13rcyajVkIikxdChmdnxxysoKODQQw+lZ8+e7Lvvvhx33HG1/hkjR47kggsuoFevXhQUFNCzZ0/atm1brkxeXh4XXnghPXv2JD8/n6OPPnrHvKKiIi677DJGjx5Ns2bNeP755znjjDOYPn06hYWFNG3alDPPPJObb7651mNPRM8jEJGUzJ07l0MOOSTbYdQJpaWllJaW0qJFC+bPn0///v2ZP38+TZrUjWPrRH+rip5HUDeiFhGpR9avX88pp5xCaWkp7s5DDz1UZ5JAddTfyEVEsqRdu3ZMnTo122HUGl0sFhHJcUoEIiI5TolARCTHKRGIiOQ4JQIRqRdOOumkXW4Ou+eee/jZz35W4XKtWrUCYMmSJZx77rlJ111Zs/R77rmHDTE96Z122ml8/fXXqYRe5ykRiEi9MGTIEMaPH19u2vjx4xkyZEhKy++zzz4899xz1f78+ETwyiuv0K5du2qvry5R81ERqbKrr4YEvS7XSJ8+EPX+nNC5557LDTfcwObNm2nevDmLFi1iyZIl9OvXj/Xr1zNo0CDWrFnD1q1bueWWWxg0aFC55RctWsQZZ5zBrFmz2LhxIxdffDFz5szhkEMO2dGtA8AVV1zBlClT2LhxI+eeey6/+c1vuO+++1iyZAknn3wyHTt2ZNKkSXTv3p3i4mI6duzI3XffvaP30ksvvZSrr76aRYsWMXDgQPr168d7771H586d+dvf/rajU7kyL7/8MrfccgtbtmwhLy+PoqIi9tprL9avX8/IkSMpLi7GzLjxxhs555xzeO2117j++uvZtm0bHTt2ZOLEiTXe9koEIlIv5OXl0bdvX1577TUGDRrE+PHjGTx4MGZGixYteOGFF2jTpg0rV67kmGOO4ayzzkraiduDDz5Iy5YtmTFjBjNmzKCgoGDHvFtvvZUOHTqwbds2TjnlFGbMmMGVV17J3XffzaRJk+jYsWO5dU2dOpXHH3+c//znP7g7Rx99NCeeeCLt27dn/vz5PPPMMzz88MOcd955PP/88/z4xz8ut3y/fv14//33MTMeeeQRbr/9du666y5uvvlm2rZty8yZMwFYs2YNK1as4Kc//SmTJ0+mR48etdYfkRKBiFRZRUfu6VRWPVSWCMqOwt2d66+/nsmTJ9OoUSO+/PJLli1bRqdOnRKuZ/LkyVx55ZUA9OrVi169eu2YN2HCBMaNG0dpaSlLly5lzpw55ebHe/fdd/nBD36wowfUs88+m3/+85+cddZZ9OjRgz59+gDJu7ouKSlh8ODBLF26lC1bttCjRw8A3nrrrXJVYe3bt+fll1/mhBNO2FGmtrqqzolrBLX97FQRyY7vf//7TJw4kQ8//JCNGzfuOJIvKipixYoVTJ06lWnTprHXXnsl7Ho6VqKzhc8++4w777yTiRMnMmPGDE4//fRK11NRf21lXVhD8q6uR44cyYgRI5g5cyYPPfTQjs9L1C11urqqbvCJoOzZqYsXg/vOZ6cqGYjUP61ateKkk05i2LBh5S4Sr127lj333JOmTZsyadIkFi9eXOF6TjjhhB0PqJ81axYzZswAQhfWu+++O23btmXZsmW8+uqrO5Zp3bo169atS7iuF198kQ0bNvDtt9/ywgsvcPzxx6f8ndauXUvnzp0BeOKJJ3ZM79+/Pw888MCO8TVr1nDsscfyzjvv8NlnnwG111V1g08EmXx2qoik35AhQ5g+ffqOJ4QBDB06lOLiYgoLCykqKuLggw+ucB1XXHEF69evp1evXtx+++307dsXCE8bO+KIIzjssMMYNmxYuS6shw8fzsCBAzn55JPLraugoICLLrqIvn37cvTRR3PppZdyxBFHpPx9xowZww9/+EOOP/74ctcfbrjhBtasWUPPnj3p3bs3kyZNYo899mDcuHGcffbZ9O7dm8GDB6f8ORVp8N1QN2oUzgTimcH27bUYmEgDp26o64+qdkPd4M8IMv3sVBGR+qbBJ4JMPztVRKS+afCJIJvPThVpaOpbVXIuqs7fKCfuI8jWs1NFGpIWLVqwatUq8vLy0tKEUWrO3Vm1ahUtWrSo0nI5kQhEpOa6dOlCSUkJK1asyHYoUoEWLVrQpUuXKi2T1kRgZgOAe4HGwCPuflvc/IuAO4Avo0kPuPsj6YxJRKqnadOmO+5olYYlbYnAzBoDY4HvASXAFDN7yd3nxBX9i7uPSFccIiJSsXReLO4LLHD3he6+BRgPDKpkGRERybB0JoLOwBcx4yXRtHjnmNkMM3vOzLomWpGZDTezYjMrVv2kiEjtSuc1gkTNCuLbNb0MPOPum83scuAJ4Lu7LOQ+DhgHYGYrzKzijkSypyOwMttBVEDx1Uxdjw/qfoyKr2ZqEl9+shnpTAQlQOwRfhdgSWwBd18VM/ow8PvKVurue9RKdGlgZsXJbuGuCxRfzdT1+KDux6j4aiZd8aWzamgKcICZ9TCzZsD5wEuxBcxs75jRs4C5aYxHREQSSNsZgbuXmtkI4HVC89HH3H22md0EFLv7S8CVZnYWUAqsBi5KVzwiIpJYWu8jcPdXgFfipv065v0vgV+mM4YMG5ftACqh+GqmrscHdT9GxVczaYmv3nVDLSIitavBdzonIiIVUyIQEclxSgRVZGZdzWySmc01s9lmdlWCMieZ2VozmxYNv060rjTGuMjMZkafvcvj3Cy4z8wWRDfzFWQwtoNitss0M/vGzK6OK5Px7Wdmj5nZcjObFTOtg5m9aWbzo9f2SZa9MCoz38wuzFBsd5jZx9Hf7wUza5dk2Qp/C2mOcYyZfRnzdzwtybIDzOyT6Pc4KoPx/SUmtkVmNi3Jsmndhsn2KRn9/bm7hioMwN5AQfS+NTAPODSuzEnA37MY4yKgYwXzTwNeJdz0dwzwnyzF2Rj4CsjP9vYDTgAKgFkx024HRkXvRwG/T7BcB2Bh9No+et8+A7H1B5pE73+fKLZUfgtpjnEMcF0Kv4FPgX2BZsD0+P+ndMUXN/8u4NfZ2IbJ9imZ/P3pjKCK3H2pu38YvV9HuPchUdcZddkg4EkP3gfaxd3TkSmnAJ+6e9bvFHf3yYQmzLEGEe52J3r9foJF/wt4091Xu/sa4E1gQLpjc/c33L00Gn2fcMNm1iTZfqnISJ9kFcVn4eEK5wHP1PbnpqKCfUrGfn9KBDVgZt2BI4D/JJh9rJlNN7NXzeywjAYWuvJ4w8ymmtnwBPNT7Qcq3c4n+T9fNrdfmb3cfSmEf1ZgzwRl6sK2HEY4w0ukst9Cuo2Iqq8eS1K1URe23/HAMnefn2R+xrZh3D4lY78/JYJqMrNWwPPA1e7+TdzsDwnVHb2B+4EXMxzece5eAAwEfm5mJ8TNT6UfqLSK7jY/C3g2wexsb7+qyOq2NLPRhBsyi5IUqey3kE4PAvsBfYClhOqXeFn/LQJDqPhsICPbsJJ9StLFEkyr8vZTIqgGM2tK+IMVuftf4+e7+zfuvj56/wrQ1Mw6Zio+d18SvS4HXiCcfseqtB+oDBgIfOjuy+JnZHv7xVhWVmUWvS5PUCZr2zK6MHgGMNSjCuN4KfwW0sbdl7n7NnffTuhLLNFnZ/W3aGZNgLOBvyQrk4ltmGSfkrHfnxJBFUX1iY8Cc9397iRlOkXlMLO+hO28KlHZNMS3u5m1LntPuKg4K67YS8AFUeuhY4C1ZaegGZT0KCyb2y/OS0BZK4wLgb8lKPM60N/M2kdVH/2jaWll4el//w84y903JCmTym8hnTHGXnf6QZLPrrRPsjQ7FfjY3UsSzczENqxgn5K531+6roQ31AHoRzj1mgFMi4bTgMuBy6MyI4DZhBYQ7wPfyWB8+0afOz2KYXQ0PTY+Izw97lNgJlCY4W3YkrBjbxszLavbj5CUlgJbCUdZlwB5wERgfvTaISpbSHj0atmyw4AF0XBxhmJbQKgbLvsN/jEquw/wSkW/hQxuvz9Hv68ZhJ3a3vExRuOnEVrKfJquGBPFF03/U9nvLqZsRrdhBfuUjP3+1MWEiEiOU9WQiEiOUyIQEclxSgQiIjlOiUBEJMcpEYiI5DglApGImW2z8j2j1lpPmGbWPbbnS5G6JK2PqhSpZza6e59sByGSaTojEKlE1B/9783sg2jYP5qeb2YTo07VJppZt2j6XhaeETA9Gr4TraqxmT0c9Tn/hpntFpW/0szmROsZn6WvKTlMiUBkp93iqoYGx8z7xt37Ag8A90TTHiB0592L0OnbfdH0+4B3PHSaV0C4IxXgAGCsux8GfA2cE00fBRwRrefydH05kWR0Z7FIxMzWu3urBNMXAd9194VR52BfuXuema0kdJuwNZq+1N07mtkKoIu7b45ZR3dCv/EHROP/D2jq7reY2WvAekIvqy961OGeSKbojEAkNZ7kfbIyiWyOeb+NndfoTif0/XQkMDXqEVMkY5QIRFIzOOb139H79wi9ZQIMBd6N3k8ErgAws8Zm1ibZSs2sEdDV3ScB/wO0A3Y5KxFJJx15iOy0m5V/gPlr7l7WhLS5mf2HcPA0JJp2JfCYmf0CWAFcHE2/ChhnZpcQjvyvIPR8mUhj4Ckza0voFfZ/3f3rWvtGIinQNQKRSkTXCArdfWW2YxFJB1UNiYjkOJ0RiIjkOJ0RiIjkOCUCEZEcp0QgIpLjlAhERHKcEoGISI77/1h/hjhLEmA3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그래프를 초기화합니다\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델은 9번째 에포크 이후에 과대적합이 시작됩니다. 9번의 에포크로 새로운 모델을 훈련하고 테스트 세트에서 평가하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 39.1 MiB for an array with shape (512, 10000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-662554a5828a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m           validation_data=(x_val, y_val))\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hot_test_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ana\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mD:\\ana\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    184\u001b[0m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[0;32m    185\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m                         \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[1;32mD:\\ana\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ana\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 39.1 MiB for an array with shape (512, 10000) and data type float64"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-100f62972f2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대략 78%의 정확도를 달성했습니다. 균형 잡힌 이진 분류 문제에서 완전히 무작위로 분류하면 50%의 정확도를 달성합니다. 이 문제는 불균형한 데이터셋을 사용하므로 무작위로 분류하면 19% 정도를 달성합니다. 여기에 비하면 이 결과는 꽤 좋은 편입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17898486197684774"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 새로운 데이터에 대해 예측하기\n",
    "\n",
    "모델 인스턴스의 `predict` 메서드는 46개 토픽에 대한 확률 분포를 반환합니다. 테스트 데이터 전체에 대한 토픽을 예측해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2246, 10000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predictions`의 각 항목은 길이가 46인 벡터입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 벡터의 원소 합은 1입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000001"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 큰 값이 예측 클래스가 됩니다. 즉, 가장 확률이 높은 클래스입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2246, 46)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 레이블과 손실을 다루는 다른 방법\n",
    "\n",
    "앞서 언급한 것처럼 레이블을 인코딩하는 다른 방법은 다음과 같이 정수 텐서로 변환하는 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 방식을 사용하려면 손실 함수 하나만 바꾸면 됩니다. 코드 3-21에 사용된 손실 함수 `categorical_crossentropy`는 레이블이 범주형 인코딩되어 있을 것이라고 기대합니다. 정수 레이블을 사용할 때는 `sparse_categorical_crossentropy`를 사용해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 손실 함수는 인터페이스만 다를 뿐이고 수학적으로는 `categorical_crossentropy`와 동일합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 충분히 큰 중간층을 두어야 하는 이유\n",
    "\n",
    "앞서 언급한 것처럼 마지막 출력이 46차원이기 때문에 중간층의 히든 유닛이 46개보다 많이 적어서는 안 됩니다. 46차원보다 훨씬 작은 중간층(예를 들면 4차원)을 두면 정보의 병목이 어떻게 나타나는지 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 76us/step - loss: 1.7939 - accuracy: 0.6252 - val_loss: 1.2377 - val_accuracy: 0.7210\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 67us/step - loss: 0.9418 - accuracy: 0.7982 - val_loss: 0.9960 - val_accuracy: 0.7800\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 66us/step - loss: 0.6361 - accuracy: 0.8642 - val_loss: 0.9066 - val_accuracy: 0.8110\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 66us/step - loss: 0.4409 - accuracy: 0.9082 - val_loss: 0.9057 - val_accuracy: 0.8230\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 66us/step - loss: 0.3241 - accuracy: 0.9293 - val_loss: 0.8642 - val_accuracy: 0.8250\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 66us/step - loss: 0.2509 - accuracy: 0.9439 - val_loss: 0.9178 - val_accuracy: 0.8230\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 65us/step - loss: 0.2079 - accuracy: 0.9473 - val_loss: 1.0127 - val_accuracy: 0.8070\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 65us/step - loss: 0.1783 - accuracy: 0.9518 - val_loss: 0.9373 - val_accuracy: 0.8170\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 66us/step - loss: 0.1637 - accuracy: 0.9540 - val_loss: 1.0583 - val_accuracy: 0.8030\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 66us/step - loss: 0.1475 - accuracy: 0.9541 - val_loss: 1.0816 - val_accuracy: 0.8100\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 66us/step - loss: 0.1422 - accuracy: 0.9538 - val_loss: 1.0478 - val_accuracy: 0.8080\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 66us/step - loss: 0.1279 - accuracy: 0.9564 - val_loss: 1.1071 - val_accuracy: 0.7980\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 65us/step - loss: 0.1293 - accuracy: 0.9550 - val_loss: 1.0898 - val_accuracy: 0.8060\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 66us/step - loss: 0.1236 - accuracy: 0.9555 - val_loss: 1.1228 - val_accuracy: 0.8010\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 66us/step - loss: 0.1176 - accuracy: 0.9573 - val_loss: 1.1405 - val_accuracy: 0.7990\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 67us/step - loss: 0.1171 - accuracy: 0.9565 - val_loss: 1.2109 - val_accuracy: 0.7980\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 66us/step - loss: 0.1090 - accuracy: 0.9572 - val_loss: 1.2037 - val_accuracy: 0.7910\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 66us/step - loss: 0.1072 - accuracy: 0.9559 - val_loss: 1.2121 - val_accuracy: 0.7950\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 66us/step - loss: 0.1024 - accuracy: 0.9579 - val_loss: 1.2393 - val_accuracy: 0.7980\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 65us/step - loss: 0.1014 - accuracy: 0.9597 - val_loss: 1.2387 - val_accuracy: 0.8030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x66e641150>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 정확도의 최고 값은 약 71%로 8% 정도 감소되었습니다. 이런 손실의 대부분 원인은 많은 정보(46개 클래스의 분할 초평면을 복원하기에 충분한 정보)를 중간층의 저차원 표현 공간으로 압축하려고 했기 때문입니다. 이 네트워크는 필요한 정보 대부분을 4차원 표현 안에 구겨 넣었지만 전부는 넣지 못했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가 실험\n",
    "\n",
    "* 더 크거나 작은 층을 사용해 보세요: 32개 유닛, 128개 유닛 등\n",
    "* 여기에서 두 개의 은닉층을 사용했습니다. 한 개의 은닉층이나 세 개의 은닉층을 사용해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "다음은 이 예제에서 배운 것들입니다.\n",
    "\n",
    "* N개의 클래스로 데이터 포인트를 분류하려면 네트워크의 마지막 `Dense` 층의 크기는 N이어야 합니다.\n",
    "* 단일 레이블, 다중 분류 문제에서는 N개의 클래스에 대한 확률 분포를 출력하기 위해 `softmax` 활성화 함수를 사용해야 합니다.\n",
    "* 이런 문제에는 항상 범주형 크로스엔트로피를 사용해야 합니다. 이 함수는 모델이 출력한 확률 분포와 타깃 분포 사이의 거리를 최소화합니다.\n",
    "* 다중 분류에서 레이블을 다루는 두 가지 방법이 있습니다.\n",
    "    * 레이블을 범주형 인코딩(또는 원-핫 인코딩)으로 인코딩하고 `categorical_crossentropy` 손실 함수를 사용합니다.\n",
    "    * 레이블을 정수로 인코딩하고 `sparse_categorical_crossentropy` 손실 함수를 사용합니다.\n",
    "* 많은 수의 범주를 분류할 때 중간층의 크기가 너무 작아 네트워크에 정보의 병목이 생기지 않도록 해야 합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
