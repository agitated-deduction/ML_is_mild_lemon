{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화 리뷰 분류: 이진 분류 예제\n",
    "\n",
    "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/%EC%BC%80%EB%9D%BC%EC%8A%A4-%EB%94%A5%EB%9F%AC%EB%8B%9D/) 책의 3장 4절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다.\n",
    "\n",
    "----\n",
    "\n",
    "2종 분류 또는 이진 분류는 아마도 가장 널리 적용된 머신 러닝 문제일 것입니다. 이 예제에서 리뷰 텍스트를 기반으로 영화 리뷰를 긍정과 부정로 분류하는 법을 배우겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB 데이터셋\n",
    "\n",
    "인터넷 영화 데이터베이스로부터 가져온 양극단의 리뷰 50,000개로 이루어진 IMDB 데이터셋을 사용하겠습니다. 이 데이터셋은 훈련 데이터 25,000개와 테스트 데이터 25,000개로 나뉘어 있고 각각 50%는 부정, 50%는 긍정 리뷰로 구성되어 있습니다.\n",
    "\n",
    "왜 훈련 데이터와 테스트 데이터를 나눌까요? 같은 데이터에서 머신 러닝 모델을 훈련하고 테스트해서는 절대 안 되기 때문입니다! 모델이 훈련 데이터에서 잘 작동한다는 것이 처음 만난 데이터에서도 잘 동작한다는 것을 보장하지 않습니다. 중요한 것은 새로운 데이터에 대한 모델의 성능입니다(사실 훈련 데이터의 레이블은 이미 알고 있기 때문에 이를 예측하는 모델은 필요하지 않습니다). 예를 들어 모델이 훈련 샘플과 타깃 사이의 매핑을 모두 외워버릴 수 있습니다. 이런 모델은 처음 만나는 데이터에서 타깃을 예측하는 작업에는 쓸모가 없습니다. 다음 장에서 이에 대해 더 자세히 살펴보겠습니다.\n",
    "\n",
    "MNIST 데이터셋처럼 IMDB 데이터셋도 케라스에 포함되어 있습니다. 이 데이터는 전처리되어 있어 각 리뷰(단어 시퀀스)가 숫자 시퀀스로 변환되어 있습니다. 여기서 각 숫자는 사전에 있는 고유한 단어를 나타냅니다.\n",
    "\n",
    "다음 코드는 데이터셋을 로드합니다(처음 실행하면 17MB 정도의 데이터가 컴퓨터에 다운로드됩니다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "매개변수 `num_words=10000`은 훈련 데이터에서 가장 자주 나타나는 단어 10,000개만 사용하겠다는 의미입니다. 드물게 나타나는 단어는 무시하겠습니다. 이렇게 하면 적절한 크기의 벡터 데이터를 얻을 수 있습니다.\n",
    "\n",
    "변수 `train_data`와 `test_data`는 리뷰의 목록입니다. 각 리뷰는 단어 인덱스의 리스트입니다(단어 시퀀스가 인코딩된 것입니다). `train_labels`와 `test_labels`는 부정을 나타내는 0과 긍정을 나타내는 1의 리스트입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 자주 등장하는 단어 10,000개로 제한했기 때문에 단어 인덱스는 10,000을 넘지 않습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재미 삼아 이 리뷰 데이터 하나를 원래 영어 단어로 어떻게 바꾸는지 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index는 단어와 정수 인덱스를 매핑한 딕셔너리입니다\n",
    "word_index = imdb.get_word_index()\n",
    "# 정수 인덱스와 단어를 매핑하도록 뒤집습니다\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# 리뷰를 디코딩합니다. \n",
    "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[10001]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this movie was lame lame lame what a build up what a let down all form no substance a terrible waste of talent and time would not recommend it to my husband's dog who will watch anything\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "신경망에 숫자 리스트를 주입할 수는 없습니다. 리스트를 텐서로 바꾸는 두 가지 방법이 있습니다:\n",
    "\n",
    "* 같은 길이가 되도록 리스트에 패딩을 추가하고 `(samples, sequence_length)` 크기의 정수 텐서로 변환합니다. 그다음 이 정수 텐서를 다룰 수 있는 층을 신경망의 첫 번째 층으로 사용합니다(`Embedding` 층을 말하며 나중에 자세히 다루겠습니다).\n",
    "* 리스트를 원-핫 인코딩하여 0과 1의 벡터로 변환합니다. 예를 들면 시퀀스 `[3, 5]`를 인덱스 3과 5의 위치는 1이고 그 외는 모두 0인 10,000차원의 벡터로 각각 변환합니다. 그다음 부동 소수 벡터 데이터를 다룰 수 있는 `Dense` 층을 신경망의 첫 번째 층으로 사용합니다.\n",
    "\n",
    "여기서는 두 번째 방식을 사용하고 이해를 돕기 위해 직접 데이터를 원-핫 벡터로 만들겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.86 GiB for an array with shape (25000, 10000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-30a4684e14de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# 훈련 데이터를 벡터로 변환합니다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorize_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;31m# 테스트 데이터를 벡터로 변환합니다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorize_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-30a4684e14de>\u001b[0m in \u001b[0;36mvectorize_sequences\u001b[1;34m(sequences, dimension)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mvectorize_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m  \u001b[1;31m# results[i]에서 특정 인덱스의 위치를 1로 만듭니다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.86 GiB for an array with shape (25000, 10000) and data type float64"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
    "    return results\n",
    "\n",
    "# 훈련 데이터를 벡터로 변환합니다\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# 테스트 데이터를 벡터로 변환합니다\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 샘플은 다음과 같이 나타납니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블은 쉽게 벡터로 바꿀 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블을 벡터로 바꿉니다\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 신경망에 주입할 데이터가 준비되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 모델 만들기\n",
    "\n",
    "입력 데이터가 벡터이고 레이블은 스칼라(1 또는 0)입니다. 아마 앞으로 볼 수 있는 문제 중에서 가장 간단할 것입니다. 이런 문제에 잘 작동하는 네트워크 종류는 `relu` 활성화 함수를 사용한 완전 연결 층(즉, `Dense(16, activation='relu')`)을 그냥 쌓은 것입니다.\n",
    "\n",
    "`Dense` 층에 전달한 매개변수(16)는 은닉 유닛의 개수입니다. 하나의 은닉 유닛은 층이 나타내는 표현 공간에서 하나의 차원이 됩니다. 2장에서 `relu` 활성화 함수를 사용한 `Dense` 층을 다음과 같은 텐서 연산을 연결하여 구현하였습니다:\n",
    "\n",
    "`output = relu(dot(W, input) + b)`\n",
    "\n",
    "16개의 은닉 유닛이 있다는 것은 가중치 행렬 `W`의 크기가 `(input_dimension, 16)`이라는 뜻입니다. 입력 데이터와 `W`를 점곱하면 입력 데이터가 16 차원으로 표현된 공간으로 투영됩니다(그리고 편향 벡터 `b`를 더하고 `relu` 연산을 적용합니다). 표현 공간의 차원을 '신경망이 내재된 표현을 학습할 때 가질 수 있는 자유도'로 이해할 수 있습니다. 은닉 유닛을 늘리면 (표현 공간을 더 고차원으로 만들면) 신경망이 더욱 복잡한 표현을 학습할 수 있지만 계산 비용이 커지고 원치 않은 패턴을 학습할 수도 있습니다(훈련 데이터에서는 성능이 향상되지만 테스트 데이터에서는 그렇지 않은 패턴입니다).\n",
    "\n",
    "`Dense` 층을 쌓을 때 두 가진 중요한 구조상의 결정이 필요합니다:\n",
    "\n",
    "* 얼마나 많은 층을 사용할 것인가\n",
    "* 각 층에 얼마나 많은 은닉 유닛을 둘 것인가\n",
    "\n",
    "4장에서 이런 결정을 하는 데 도움이 되는 일반적인 원리를 배우겠습니다. 당분간은 저를 믿고 선택한 다음 구조를 따라 주세요.\n",
    "\n",
    "* 16개의 은닉 유닛을 가진 두 개의 은닉층\n",
    "* 현재 리뷰의 감정을 스칼라 값의 예측으로 출력하는 세 번째 층\n",
    "\n",
    "중간에 있는 은닉층은 활성화 함수로 `relu`를 사용하고 마지막 층은 확률(0과 1 사이의 점수로, 어떤 샘플이 타깃 '1'일 가능성이 높다는 것은 그 리뷰가 긍정일 가능성이 높다는 것을 의미합니다)을 출력하기 위해 시그모이드 활성화 함수를 사용합니다. `relu`는 음수를 0으로 만드는 함수입니다. 시그모이드는 임의의 값을 [0, 1] 사이로 압축하므로 출력 값을 확률처럼 해석할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음이 이 신경망의 모습입니다:\n",
    "\n",
    "![3-layer network](https://s3.amazonaws.com/book.keras.io/img/ch3/3_layer_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 이 신경망의 케라스 구현입니다. 이전에 보았던 MNIST 예제와 비슷합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 손실 함수와 옵티마이저를 선택해야 합니다. 이진 분류 문제이고 신경망의 출력이 확률이기 때문에(네트워크의 끝에 시그모이드 활성화 함수를 사용한 하나의 유닛으로 된 층을 놓았습니다), `binary_crossentropy` 손실이 적합합니다. 이 함수가 유일한 선택은 아니고 예를 들어 `mean_squared_error`를 사용할 수도 있습니다. 확률을 출력하는 모델을 사용할 때는 크로스엔트로피가 최선의 선택입니다. 크로스엔트로피는 정보 이론 분야에서 온 개념으로 확률 분포 간의 차이를 측정합니다. 여기에서는 원본 분포와 예측 분포 사이를 측정합니다.\n",
    "\n",
    "다음은 `rmsprop` 옵티마이저와 `binary_crossentropy` 손실 함수로 모델을 설정하는 단계입니다. 훈련하는 동안 정확도를 사용해 모니터링하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스에 `rmsprop`, `binary_crossentropy`, `accuracy`가 포함되어 있기 때문에 옵티마이저, 손실 함수, 측정 지표를 문자열로 지정하는 것이 가능합니다. 이따금 옵티마이저의 매개변수를 바꾸거나 자신만의 손실 함수, 측정 함수를 전달해야 할 경우가 있습니다. 전자의 경우에는 옵티마이저 파이썬 클래스를 사용해 객체를 직접 만들어 `optimizer` 매개변수에 전달하면 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "후자의 경우는 `loss`와 `metrics` 매개변수에 함수 객체를 전달하면 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 검증\n",
    "\n",
    "훈련하는 동안 처음 본 데이터에 대한 모델의 정확도를 측정하기 위해서는 원본 훈련 데이터에서 10,000의 샘플을 떼어서 검증 세트를 만들어야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape\n",
    "#x_val.ndim\n",
    "#x_val.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "이제 모델을 512개 샘플씩 미니 배치를 만들어 20번의 에포크 동안 훈련시킵니다(`x_train`과 `y_train` 텐서에 있는 모든 샘플에 대해 20번 반복합니다). 동시에 따로 떼어 놓은 10,000개의 샘플에서 손실과 정확도를 측정할 것입니다. 이렇게 하려면 `validation_data` 매개변수에 검증 데이터를 전달해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "15000/15000 [==============================] - 2s 166us/step - loss: 0.5291 - accuracy: 0.7767 - val_loss: 0.3850 - val_accuracy: 0.8684\n",
      "Epoch 2/30\n",
      "15000/15000 [==============================] - 2s 154us/step - loss: 0.3086 - accuracy: 0.8999 - val_loss: 0.3087 - val_accuracy: 0.8838\n",
      "Epoch 3/30\n",
      "15000/15000 [==============================] - 2s 152us/step - loss: 0.2266 - accuracy: 0.9265 - val_loss: 0.2786 - val_accuracy: 0.8918\n",
      "Epoch 4/30\n",
      "15000/15000 [==============================] - 2s 154us/step - loss: 0.1780 - accuracy: 0.9427 - val_loss: 0.2725 - val_accuracy: 0.8923\n",
      "Epoch 5/30\n",
      "15000/15000 [==============================] - 2s 157us/step - loss: 0.1427 - accuracy: 0.9558 - val_loss: 0.2874 - val_accuracy: 0.8880\n",
      "Epoch 6/30\n",
      "15000/15000 [==============================] - 2s 156us/step - loss: 0.1192 - accuracy: 0.9632 - val_loss: 0.2970 - val_accuracy: 0.8852\n",
      "Epoch 7/30\n",
      "15000/15000 [==============================] - 2s 156us/step - loss: 0.0976 - accuracy: 0.9733 - val_loss: 0.3387 - val_accuracy: 0.8719\n",
      "Epoch 8/30\n",
      "15000/15000 [==============================] - 2s 155us/step - loss: 0.0797 - accuracy: 0.9778 - val_loss: 0.3220 - val_accuracy: 0.8829\n",
      "Epoch 9/30\n",
      "15000/15000 [==============================] - 2s 156us/step - loss: 0.0653 - accuracy: 0.9831 - val_loss: 0.3475 - val_accuracy: 0.8806\n",
      "Epoch 10/30\n",
      "15000/15000 [==============================] - 2s 157us/step - loss: 0.0520 - accuracy: 0.9877 - val_loss: 0.3794 - val_accuracy: 0.8744\n",
      "Epoch 11/30\n",
      "15000/15000 [==============================] - 2s 159us/step - loss: 0.0449 - accuracy: 0.9895 - val_loss: 0.4280 - val_accuracy: 0.8721\n",
      "Epoch 12/30\n",
      "15000/15000 [==============================] - 2s 162us/step - loss: 0.0348 - accuracy: 0.9932 - val_loss: 0.4288 - val_accuracy: 0.8752\n",
      "Epoch 13/30\n",
      "15000/15000 [==============================] - 2s 155us/step - loss: 0.0274 - accuracy: 0.9946 - val_loss: 0.4560 - val_accuracy: 0.8739\n",
      "Epoch 14/30\n",
      "15000/15000 [==============================] - 2s 158us/step - loss: 0.0216 - accuracy: 0.9963 - val_loss: 0.4890 - val_accuracy: 0.8724\n",
      "Epoch 15/30\n",
      "15000/15000 [==============================] - 2s 155us/step - loss: 0.0194 - accuracy: 0.9961 - val_loss: 0.5241 - val_accuracy: 0.8691\n",
      "Epoch 16/30\n",
      "15000/15000 [==============================] - 2s 155us/step - loss: 0.0107 - accuracy: 0.9993 - val_loss: 0.5640 - val_accuracy: 0.8702\n",
      "Epoch 17/30\n",
      "15000/15000 [==============================] - 2s 156us/step - loss: 0.0101 - accuracy: 0.9993 - val_loss: 0.5982 - val_accuracy: 0.8687\n",
      "Epoch 18/30\n",
      "15000/15000 [==============================] - 2s 156us/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.6304 - val_accuracy: 0.8680\n",
      "Epoch 19/30\n",
      "15000/15000 [==============================] - 2s 158us/step - loss: 0.0043 - accuracy: 0.9997 - val_loss: 0.6589 - val_accuracy: 0.8670\n",
      "Epoch 20/30\n",
      "15000/15000 [==============================] - 2s 158us/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.6896 - val_accuracy: 0.8659\n",
      "Epoch 21/30\n",
      "15000/15000 [==============================] - 2s 158us/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.7314 - val_accuracy: 0.8670\n",
      "Epoch 22/30\n",
      "15000/15000 [==============================] - 3s 185us/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.7573 - val_accuracy: 0.8627\n",
      "Epoch 23/30\n",
      "15000/15000 [==============================] - 2s 163us/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.7864 - val_accuracy: 0.8651\n",
      "Epoch 24/30\n",
      "15000/15000 [==============================] - 2s 163us/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.8476 - val_accuracy: 0.8583\n",
      "Epoch 25/30\n",
      "15000/15000 [==============================] - 3s 186us/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.8611 - val_accuracy: 0.8639\n",
      "Epoch 26/30\n",
      "15000/15000 [==============================] - 3s 182us/step - loss: 6.8906e-04 - accuracy: 0.9999 - val_loss: 0.8896 - val_accuracy: 0.8635\n",
      "Epoch 27/30\n",
      "15000/15000 [==============================] - 3s 168us/step - loss: 5.5660e-04 - accuracy: 0.9999 - val_loss: 1.0841 - val_accuracy: 0.8525\n",
      "Epoch 28/30\n",
      "15000/15000 [==============================] - 2s 148us/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.9531 - val_accuracy: 0.8597\n",
      "Epoch 29/30\n",
      "15000/15000 [==============================] - 2s 146us/step - loss: 3.3646e-04 - accuracy: 0.9999 - val_loss: 0.9911 - val_accuracy: 0.8599\n",
      "Epoch 30/30\n",
      "15000/15000 [==============================] - 2s 148us/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 1.0215 - val_accuracy: 0.8620\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=30,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU를 사용해도 에포크마다 2초가 걸리지 않습니다. 전체 훈련은 20초 이상 걸립니다. 에포크가 끝날 때마다 10,000개의 검증 샘플 데이터에서 손실과 정확도를 계산하기 때문에 약간씩 지연됩니다.\n",
    "\n",
    "`model.fit()` 메서드는 `History` 객체를 반환합니다. 이 객체는 훈련하는 동안 발생한 모든 정보를 담고 있는 딕셔너리인 `history` 속성을 가지고 있습니다. 한 번 확인해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 딕셔너리는 훈련과 검증하는 동안 모니터링할 측정 지표당 하나씩 모두 네 개의 항목을 담고 있습니다. 맷플롯립을 사용해 훈련과 검증 데이터에 대한 손실과 정확도를 그려 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# ‘bo’는 파란색 점을 의미합니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# ‘b’는 파란색 실선을 의미합니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그래프를 초기화합니다\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "점선은 훈련 손실과 정확도이고 실선은 검증 손실과 정확도입니다. 신경망의 무작위한 초기화 때문에 사람마다 결과거 조금 다를 수 있습니다.\n",
    "\n",
    "여기에서 볼 수 있듯이 훈련 손실이 에포크마다 감소하고 훈련 정확도는 에포크마다 증가합니다. 경사 하강법 최적화를 사용했을 때 반복마다 최소화되는 것이 손실이므로 기대했던 대로입니다. 검증 손실과 정확도는 이와 같지 않습니다. 4번째 에포크에서 그래프가 역전되는 것 같습니다. 이것이 훈련 세트에서 잘 작동하는 모델이 처음 보는 데이터에 잘 작동하지 않을 수 있다고 앞서 언급한 경고의 한 사례입니다. 정확한 용어로 말하면 과대적합되었다고 합니다. 2번째 에포크 이후부터 훈련 데이터에 과도하게 최적화되어 훈련 데이터에 특화된 표현을 학습하므로 훈련 세트 이외의 데이터에는 일반화되지 못합니다.\n",
    "\n",
    "이런 경우에 과대적합을 방지하기 위해서 3번째 에포크 이후에 훈련을 중지할 수 있습니다. 일반적으로 4장에서 보게 될 과대적합을 완화하는 다양한 종류의 기술을 사용할 수 있습니다.\n",
    "\n",
    "처음부터 다시 새로운 신경망을 4번의 에포크 동안만 훈련하고 테스트 데이터에서 평가해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 3s 106us/step - loss: 0.4882 - accuracy: 0.8119\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.2756 - accuracy: 0.9090\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.2082 - accuracy: 0.9282\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.1709 - accuracy: 0.9408\n",
      "25000/25000 [==============================] - 5s 201us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2959324370956421, 0.883840024471283]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아주 단순한 방식으로도 87%의 정확도를 달성했습니다. 최고 수준의 기법을 사용하면 95%에 가까운 성능을 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련된 모델로 새로운 데이터에 대해 예측하기\n",
    "\n",
    "모델을 훈련시킨 후에 이를 실전 환경에서 사용하고 싶을 것입니다. `predict` 메서드를 사용해서 어떤 리뷰가 긍정일 확률을 예측할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19031958],\n",
       "       [0.9983675 ],\n",
       "       [0.82787424],\n",
       "       ...,\n",
       "       [0.0931106 ],\n",
       "       [0.0723435 ],\n",
       "       [0.57432854]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19031958]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서처럼 이 모델은 어떤 샘플에 대해 확신을 가지고 있지만(0.99 또는 그 이상, 0.01 또는 그 이하) 어떤 샘플에 대해서는 확신이 부족합니다(0.6, 0.4). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가 실험\n",
    "\n",
    "* 여기에서는 두 개의 은닉층을 사용했습니다. 한 개 또는 세 개의 은닉층을 사용하고 검증과 테스트 정확도에 어떤 영향을 미치는지 확인해 보세요.\n",
    "* 층의 은닉 유닛을 추가하거나 줄여 보세요: 32개 유닛, 64개 유닛 등\n",
    "* `binary_crossentropy` 대신에 `mse` 손실 함수를 사용해 보세요.\n",
    "* `relu` 대신에 `tanh` 활성화 함수(초창기 신경망에서 인기 있었던 함수입니다)를 사용해 보세요.\n",
    "\n",
    "다음 실험을 진행하면 여기에서 선택한 구조가 향상의 여지는 있지만 어느 정도 납득할 만한 수준이라는 것을 알게 것입니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "다음은 이 예제에서 배운 것들입니다:\n",
    "\n",
    "* 원본 데이터를 신경망에 텐서로 주입하기 위해서는 꽤 많은 전처리가 필요합니다. 단어 시퀀스는 이진 벡터로 인코딩될 수 있고 다른 인코딩 방식도 있습니다.\n",
    "* `relu` 활성화 함수와 함께 `Dense` 층을 쌓은 네트워크는 (감성 분류를 포함하여) 여러 종류의 문제에 적용할 수 있어서 앞으로 자주 사용하게 될 것입니다.\n",
    "* (출력 클래스가 두 개인) 이진 분류 문제에서 네트워크는 하나의 유닛과 `sigmoid` 활성화 함수를 가진 `Dense` 층으로 끝나야 합니다. 이 신경망의 출력은 확률을 나타내는 0과 1 사이의 스칼라 값입니다.\n",
    "* 이진 분류 문제에서 이런 스칼라 시그모이드 출력에 대해 사용할 손실 함수는 `binary_crossentropy`입니다.\n",
    "* `rmsprop` 옵티마이저는 문제에 상관없이 일반적으로 충분히 좋은 선택입니다. 걱정할 거리가 하나 줄은 셈입니다.\n",
    "* 훈련 데이터에 대해 성능이 향상됨에 따라 신경망은 과대적합되기 시작하고 이전에 본적 없는 데이터에서는 결과가 점점 나빠지게 됩니다. 항상 훈련 세트 이외의 데이터에서 성능을 모니터링해야 합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
